services:
  web:
    build:
      context: .
      dockerfile: ./compose/local/fastapi/Dockerfile
    image: companion_web
    command: /start
    volumes:
      - .:/app
    ports:
      - 8010:8000
    env_file:
      - .env/.dev
    depends_on:
      - redis
      - ollama
    networks:
      - companion-network

  redis:
    image: redis:7-alpine
    networks:
      - companion-network

  ollama:
    image: ollama/ollama:latest
    container_name: companion_ollama
    ports:
      - "11434:11434"
    volumes:
      - companion_ollama_data:/root/.ollama
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    restart: always
    entrypoint: ["/bin/sh", "-c"]
    command: >
      "ollama serve &
      sleep 10 &&
      ollama list | grep -q gemma2:2b || ollama pull gemma2:2b &&
      wait"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11434/api/tags"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - companion-network

  celery_worker:
    build:
      context: .
      dockerfile: ./compose/local/fastapi/Dockerfile
    image: companion_worker
    command: /start-celeryworker
    volumes:
      - .:/app
    env_file:
      - .env/.dev
    depends_on:
      - redis
      - ollama
    networks:
      - companion-network

  celery_beat:
    build:
      context: .
      dockerfile: ./compose/local/fastapi/Dockerfile
    image: companion_celery_beat
    command: /start-celerybeat
    volumes:
      - .:/app
    env_file:
      - .env/.dev
    depends_on:
      - redis
    networks:
      - companion-network

  flower:
    build:
      context: .
      dockerfile: ./compose/local/fastapi/Dockerfile
    image: companion_celery_flower
    command: /start-flower
    volumes:
      - .:/app
    env_file:
      - .env/.dev
    ports:
      - 5557:5555
    depends_on:
      - redis
    networks:
      - companion-network

  frontend:
    build:
      context: ../companion-frontend
      dockerfile: Dockerfile
    ports:
      - "3000:3000"
    environment:
      - NEXT_PUBLIC_API_URL=http://localhost:8010/api/v1
      - NEXT_PUBLIC_WS_URL=ws://localhost:8010
    depends_on:
      - web
    networks:
      - companion-network

volumes:
  companion_ollama_data:

networks:
  companion-network:
    driver: bridge